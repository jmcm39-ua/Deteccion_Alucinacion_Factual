import spacy
from transformers import AutoTokenizer, AutoModelForSequenceClassification, MarianMTModel, MarianTokenizer
import torch
from difflib import get_close_matches
from huggingface_hub import login
import requests
from difflib import get_close_matches
import sys
import json
import warnings
from openai_service import extraer_sujeto_openai
warnings.filterwarnings("ignore")
from transformers.utils import logging
logging.set_verbosity_error()



# Modelos spacy para detecci√≥n sujetos
nlp = spacy.load("es_core_news_md")
nlp_en = spacy.load("en_core_web_trf")


# Modelo NLI
tokenizer = AutoTokenizer.from_pretrained("PlanTL-GOB-ES/roberta-large-bne-te")
model = AutoModelForSequenceClassification.from_pretrained("PlanTL-GOB-ES/roberta-large-bne-te")
model.eval()

# Modelo traducci√≥n ingl√©s
modelo_trad = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-es-en")
tokenizer_trad = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-es-en")

#Rigoberta asociacion -> Castellano flor,
modelo_nli = AutoModelForSequenceClassification.from_pretrained("roberta-large-mnli")
tokenizer_nli = AutoTokenizer.from_pretrained("roberta-large-mnli")

#Funci√≥n para traducir de espa√±ol a ingl√©s
def traducir_es_en(texto):
    inputs = tokenizer_trad([texto], return_tensors="pt", truncation=True, padding=True)
    translated = modelo_trad.generate(**inputs)
    return tokenizer_trad.decode(translated[0], skip_special_tokens=True)

#Funci√≥n de extracci√≥n de oraciones
def dividir_en_oraciones(texto):
    doc = nlp(texto)
    return [sent.text.strip() for sent in doc.sents]

#Funci√≥n de extracci√≥n de keywords
def extraer_keywords(oracion):
    doc = nlp(oracion)
    return [ent.text for ent in doc.ents if ent.label_ in {"PER", "ORG", "LOC", "MISC"}]


#Funci√≥n de extracci√≥n de sujeto
def extraer_sujeto(oracion):
    doc_es = nlp(oracion)
    
    entidades_es = [ent.text for ent in doc_es.ents if ent.label_ in {"PER", "ORG"}]
    if entidades_es:
        return entidades_es[0]

    doc_en = nlp_en(oracion)
    
    entidades_en = [ent.text for ent in doc_en.ents if ent.label_ in {"PER", "ORG"}]
    if entidades_en:
        return entidades_en[0]

    for token in doc_es:
        if token.dep_ in {"nsubj", "nsubj:pass"}:
            # Devuelve el sujeto sin modificadores
            sujeto = " ".join([w.text for w in token.subtree])
            # Filtro de palabras comunes
            filtros = {"el", "la", "los", "las", "un", "una", "unos", "unas", "este", "ese", "poeta", "presidente", "doctor", "profesor"}
            palabras = [p for p in sujeto.split() if p.lower() not in filtros]
            return " ".join(palabras)

    return None

#Funci√≥n de b√∫squeda de entidades
def buscar_entidad_wikidata(nombre):
        #print(f"Buscando entidad en Wikidata para: {nombre}")
        
    url = f"https://www.wikidata.org/w/api.php?action=wbsearchentities&search={nombre}&language=es&format=json"
    response = requests.get(url)
    data = response.json()

    if 'search' in data and data['search']:
        best_match = data['search'][0]
        entity_id = best_match['id']
        label = best_match['label']
        
        url_entity = f"https://www.wikidata.org/w/api.php?action=wbgetentities&ids={entity_id}&sites=wikidata&props=descriptions&languages=es&format=json"
        response_entity = requests.get(url_entity)
        data_entity = response_entity.json()

        description = data_entity.get('entities', {}).get(entity_id, {}).get('descriptions', {}).get('es', {}).get('value', 'Descripci√≥n no disponible')

        #print(f"Entidad encontrada: {label} ({entity_id})")
        return entity_id, label, description
    
    return None, None, None

# Funci√≥n de obtenci√≥n de tipos de la entidad
def obtener_tipo_entidad(qid):
    try:
        url = f"https://www.wikidata.org/w/api.php?action=wbgetentities&ids={qid}&sites=wikidata&props=claims&format=json"
        response = requests.get(url)
        data = response.json()
        
        if 'entities' not in data or qid not in data['entities']:
            #print(f"No se encontraron datos para el QID: {qid}")
            return []

        claims = data.get("entities", {}).get(qid, {}).get("claims", {})

        if "P31" in claims:
            tipos = [c.get('mainsnak', {}).get('datavalue', {}).get('value', {}).get('id') for c in claims["P31"]]
            #print(f"Tipos para {qid}: {tipos}")
            return tipos

        return []
    except Exception as e:
        #print(f"Error al obtener tipo de entidad: {e}")
        return []
    
#Funci√≥n de obtenci√≥n de label
def obtener_label(QID, idioma='es'):
    try:
        url = f"https://www.wikidata.org/wiki/Special:EntityData/{QID}.json"
        response = requests.get(url)
        data = response.json()
        entity = data['entities'][QID]
        labels = entity['labels']
        return labels.get(idioma, {}).get('value', QID)
    except:
        return QID

#Funci√≥n de obtenci√≥n de fechas
def obtener_fecha_publicacion(qid_obra):
    url = f"https://www.wikidata.org/w/api.php?action=wbgetentities&ids={qid_obra}&format=json&props=claims"
    response = requests.get(url)
    data = response.json()
    claims = data.get('entities', {}).get(qid_obra, {}).get('claims', {})
    if 'P577' in claims:
        fecha = claims['P577'][0].get('mainsnak', {}).get('datavalue', {}).get('value', {}).get('time', '')
        return fecha
    return None

#Funci√≥n de obtenci√≥n de hechos
def recuperar_hechos(qid):
    try:
        #print(f"Recuperando hechos para la entidad: {qid}")

        url = f"https://www.wikidata.org/w/api.php?action=wbgetentities&ids={qid}&sites=wikidata&props=claims|descriptions&format=json"
        response = requests.get(url)
        data = response.json()
        entity_data = data.get('entities', {}).get(qid, {}).get('claims', {})
        entity = data.get('entities', {}).get(qid, {})

        hechos = []

        # Descripci√≥n corta
        descripcion_corta = entity.get('descriptions', {}).get('es', {}).get('value', '')
        if descripcion_corta:
            hechos.append(f"{descripcion_corta}.")

        propiedades = {
            # üßë Personas
            'P106': 'Ocupaci√≥n',
            'P166': 'Premio recibido',
            'P19': 'Lugar de nacimiento',
            'P20': 'Lugar de fallecimiento',
            'P569': 'Fecha de nacimiento',
            'P570': 'Fecha de fallecimiento',
            'P800': 'Obra destacada',
            'P27': 'Nacionalidad',
            'P39': 'Cargo o posici√≥n',
            'P69': 'Educaci√≥n',
            'P26': 'C√≥nyuge',
            'P22': 'Padre',
            'P25': 'Madre',
            'P734': 'Apellido',
            'P735': 'Nombre de pila',
            'P161': 'Pel√≠culas en las que ha actuado',
            'P175': 'Int√©rprete',
            'P3095': 'Personaje interpretado',
            'P108': 'Empleado en',

            # üé¨ Pel√≠culas / Producciones audiovisuales
            'P57': 'Director',
            'P58': 'Guionista',
            'P161': 'Reparto',
            'P272': 'Productora',
            'P364': 'Idioma original',
            'P577': 'Fecha de publicaci√≥n/estreno',
            'P1040': 'Editor',
            'P2130': 'Costo de producci√≥n',
            'P2142': 'Ingresos brutos',
            'P1476': 'T√≠tulo oficial',

            # üìö Libros / Obras
            'P50': 'Autor',
            'P577': 'Fecha de publicaci√≥n',
            'P110': 'Ilustrador',
            'P291': 'Lugar de publicaci√≥n',
            'P364': 'Idioma de la obra',
            'P1476': 'T√≠tulo oficial',
            'P1680': 'Descripci√≥n corta',
            'P123': 'Editorial',
            'P655': 'T√≠tulo original',
            'P98': 'Editor literario',

            # üè¢ Organizaciones / Empresas
            'P112': 'Fundador',
            'P159': 'Sede',
            'P571': 'Fecha de fundaci√≥n',
            'P452': 'Industria',
            'P1454': 'Accionista',
            'P127': 'Propietario',
            'P749': 'Empresa matriz',
            'P1128': 'Empleados',
            'P2139': 'Recuento de ingresos',
            'P2403': 'Autoridad reguladora',

            # üåç Lugares
            'P17': 'Pa√≠s',
            'P131': 'Ubicaci√≥n administrativa',
            'P625': 'Coordenadas',
            'P2046': '√Årea',
            'P1082': 'Poblaci√≥n',
            'P856': 'P√°gina web oficial',
            'P1448': 'Nombre oficial',
            'P1464': 'Categor√≠a de patrimonio',

            # üåå Objetos astron√≥micos / Planetas
            'P2583': 'Clase espectral',
            'P2120': 'Gravedad superficial',
            'P2067': 'Masa',
            'P2050': '√ìrbita',
            'P2146': 'Di√°metro',
            'P3984': '√ìrbita de',
            'P3996': 'Luna de',
            'P376': '√ìrbita alrededor de',
            'P625': 'Coordenadas celestes',
            'P59': 'Constelaci√≥n',

            # üîÅ Relaciones / colaboraciones / composici√≥n
            'P361': 'Parte de',
            'P527': 'Tiene como parte',
            'P176': 'Fabricante',
            'P137': 'Patrocinado por',
            'P710': 'Participante',
            'P155': 'Predecesor',
            'P156': 'Sucesor',
            'P144': 'Basado en',
            'P50': 'Autor de la obra',
            'P629': 'Versi√≥n o edici√≥n de',

            # üèÜ Deportes (por si aparecen atletas)
            'P54': 'Miembro de equipo deportivo',
            'P1350': 'N√∫mero de victorias',
            'P1351': 'N√∫mero de derrotas',
            'P641': 'Deporte practicado',

            # üé∂ M√∫sica
            'P676': 'N√∫mero de cat√°logo',
            'P435': 'ID MusicBrainz',

            # üë®‚Äçüíª Tecnolog√≠a / Software
            'P178': 'Desarrollador',
            'P348': 'Versi√≥n',
            'P275': 'Licencia',
            'P1072': 'Sitio web oficial del software',

            # üèõ Cultura / Historia
            'P128': 'Lugar de exposici√≥n',
            'P573': 'Per√≠odo hist√≥rico',
            'P2189': 'Proyecto art√≠stico',

            # ü¶† Biolog√≠a / Ciencia
            'P27': 'Especie',
            'P2219': 'Organismo relacionado',
            'P2313': 'Funci√≥n biol√≥gica',
            'P679': 'Propiedades gen√©ticas',

            # üöó Veh√≠culos / Transportes
            'P414': 'Compa√±√≠a a√©rea',
            'P1098': 'Propietario del veh√≠culo',
            'P3407': 'Tipo de transporte',

            # üè† Construcci√≥n / Arquitectura
            'P279': 'Tipo de edificio',
            'P152': 'Material de construcci√≥n',
            'P3179': 'Arquitecto',

            # üçΩ Alimentos
            'P476': 'Ingrediente principal',
            'P2067': 'M√©todo de preparaci√≥n',

            # üåø Medio ambiente / Naturaleza
            'P720': 'Habita en',
            'P1632': 'Requiere',

            # üí° Invenciones
            'P1799': 'Nombre del invento',
            'P3504': 'Patente',

            
        }


        for pid, descripcion in propiedades.items():
            if pid in entity_data:
                for item in entity_data[pid]:
                    mainsnak = item.get('mainsnak', {})
                    datavalue = mainsnak.get('datavalue', {}).get('value', {})

                    # Identificadores de entidad (QIDs)
                    if isinstance(datavalue, dict) and 'id' in datavalue:
                        qid = datavalue['id']
                        etiqueta = obtener_label(qid)
                        texto = f"{descripcion}: {etiqueta}"

                        # Fecha asociada al premio
                        if pid == 'P166':
                            qualifiers = item.get('qualifiers', {})
                            if 'P585' in qualifiers:
                                fecha_val = qualifiers['P585'][0].get('datavalue', {}).get('value', {}).get('time', '')
                                if fecha_val:
                                    texto += f" (fecha: {fecha_val[1:11]})"  # Quitar el signo +

                        # Fecha de publicaci√≥n de obra destacada
                        elif pid == 'P800':
                            fecha_pub = obtener_fecha_publicacion(qid)
                            if fecha_pub:
                                texto += f" (fecha: {fecha_pub[1:11]})"

                        hechos.append(texto)

                    # Fechas puras (como P569, P570)
                    elif isinstance(datavalue, dict) and 'time' in datavalue:
                        fecha = datavalue['time'][1:11]
                        hechos.append(f"{descripcion}: {fecha}")

                    # Strings simples
                    elif isinstance(datavalue, str):
                        hechos.append(f"{descripcion}: {datavalue}")

        return hechos

    except Exception as e:
        #print(f"Error al recuperar hechos: {e}")
        return []


def resolver_qids(qids):
    etiquetas = {}
    if not qids:
        return etiquetas

    ids_str = "|".join(set(qids))
    url = f"https://www.wikidata.org/w/api.php?action=wbgetentities&ids={ids_str}&format=json&props=labels&languages=es"
    response = requests.get(url)
    data = response.json()

    for qid, info in data.get('entities', {}).items():
        etiqueta = info.get('labels', {}).get('es', {}).get('value', 'Desconocido')
        etiquetas[qid] = etiqueta

    return etiquetas
    


def generar_oracion_resumen_con_etiquetas(nombre, hechos, tipos_etiquetas):
    import re

    # Resolver etiquetas de hechos
    qids = re.findall(r'Q\d+', " ".join(hechos))
    etiquetas = resolver_qids(qids)

    # Resolver etiquetas de tipos
    tipos_qids = [t for t in tipos_etiquetas if t.startswith("Q")]
    etiquetas_tipos = resolver_qids(tipos_qids)
    tipos_legibles = [etiquetas_tipos.get(t, t) for t in tipos_etiquetas]

    # Reemplazar QIDs en los hechos
    hechos_legibles = []
    for h in hechos:
        for q in qids:
            if q in h:
                h = h.replace(q, etiquetas.get(q, q))
        hechos_legibles.append(h)

    resumen = f"Seg√∫n Wikidata, {nombre}"

    # Clasificaci√≥n por tipo de propiedad
    def extraer(prop): return [h for h in hechos_legibles if h.startswith(prop)]
    def extraer_valor(prop): return [h.replace(f"{prop}: ", "") for h in hechos_legibles if h.startswith(prop)]

    partes = []

    descripcion = [h for h in hechos_legibles if h.endswith(".") and not ":" in h]
    if descripcion:
        partes.append(descripcion[0].rstrip("."))
    if tipos_legibles:
        partes.append(f"es {', '.join(set(tipos_legibles))}")

    # Datos personales
    ocup = extraer_valor("Ocupaci√≥n")
    #premio = extraer_valor("Premio recibido")
    nac = extraer("Fecha de nacimiento")
    lugar_nac = extraer_valor("Lugar de nacimiento")
    falle = extraer("Fecha de fallecimiento")
    lugar_falle = extraer_valor("Lugar de fallecimiento")
    nacionalidad = extraer_valor("Nacionalidad")
    educacion = extraer_valor("Educaci√≥n")
    conyuge = extraer_valor("C√≥nyuge")
    padre = extraer_valor("Padre")
    madre = extraer_valor("Madre")
    cargo = extraer_valor("Cargo o posici√≥n")
    apellido = extraer_valor("Apellido")
    nombre_pila = extraer_valor("Nombre de pila")
    peliculas = extraer_valor("Pel√≠culas en las que ha actuado")
    interprete = extraer_valor("Int√©rprete")
    personaje = extraer_valor("Personaje interpretado")
    #obra = extraer_valor("Obra destacada")
    companias = extraer_valor("Empleado en") 

    # Informaci√≥n de nacimiento
    if lugar_nac and nac:
        partes.append(f"naci√≥ en {', '.join(set(lugar_nac))} el {nac[0].replace('Fecha de nacimiento: +', '').split('T')[0]}")

    # Informaci√≥n de fallecimiento
    if lugar_falle and falle:
        partes.append(f"falleci√≥ en {', '.join(set(lugar_falle))} el {falle[0].replace('Fecha de fallecimiento: +', '').split('T')[0]}")

    # Informaci√≥n de nacionalidad
    if nacionalidad:
        partes.append(f"de nacionalidad {', '.join(set(nacionalidad))}")

    # Informaci√≥n de educaci√≥n
    if educacion:
        partes.append(f"estudi√≥ en {', '.join(set(educacion))}")

    # Informaci√≥n de c√≥nyuge
    if conyuge:
        partes.append(f"su c√≥nyuge es {', '.join(set(conyuge))}")

    # Informaci√≥n de los padres
    if padre or madre:
        parentesco = []
        if padre: parentesco.append(f"padre: {', '.join(set(padre))}")
        if madre: parentesco.append(f"madre: {', '.join(set(madre))}")
        partes.append("tiene como " + " y ".join(parentesco))

    # Informaci√≥n de ocupaci√≥n
    if ocup:
        partes.append(f"fue {', '.join(set(ocup))}")

    # Informaci√≥n de cargos
    if cargo:
        partes.append(f"ocup√≥ cargos como {', '.join(set(cargo))}")

    # Informaci√≥n sobre apellidos y nombres
    if apellido or nombre_pila:
        nombres = []
        if apellido: nombres.append(f"apellido: {', '.join(set(apellido))}")
        if nombre_pila: nombres.append(f"nombre de pila: {', '.join(set(nombre_pila))}")
        partes.append("con " + " y ".join(nombres))

    # Informaci√≥n sobre pel√≠culas y personajes interpretados
    if peliculas or interprete or personaje:
        peliculas_info = []
        if peliculas: peliculas_info.append(f"actu√≥ en pel√≠culas como {', '.join(set(peliculas))}")
        if interprete: peliculas_info.append(f"fue int√©rprete de {', '.join(set(interprete))}")
        if personaje: peliculas_info.append(f"interpret√≥ personajes como {', '.join(set(personaje))}")
        partes.append(" ".join(peliculas_info))

# Premios con fechas completas
    premios = [h for h in hechos_legibles if h.startswith("Premio recibido")]
    premios_format = []
    for p in premios:
        if "@" in p:
            nombre, fecha = p.split("@")
            nombre = nombre.replace("Premio recibido: ", "").strip()
            premios_format.append(f"{nombre} en {fecha}")
        else:
            premios_format.append(p.replace("Premio recibido: ", ""))
    if premios_format:
        partes.append(f"recibi√≥ premios como {', '.join(set(premios_format))}")

    # Obras con fechas completas
    obras = [h for h in hechos_legibles if h.startswith("Obra destacada")]
    obras_format = []
    for o in obras:
        if "@" in o:
            nombre, fecha = o.split("@")
            nombre = nombre.replace("Obra destacada: ", "").strip()
            obras_format.append(f"{nombre} en {fecha}")
        else:
            obras_format.append(o.replace("Obra destacada: ", ""))
    if obras_format:
        partes.append(f"es conocido por obras como {', '.join(set(obras_format))}")

    if companias:
        partes.append(f"trabaj√≥ en {', '.join(set(companias))}")

    
    # Datos de producciones audiovisuales
    director = extraer_valor("Director")
    guionista = extraer_valor("Guionista")
    reparto = extraer_valor("Reparto")
    productora = extraer_valor("Productora")
    idioma_original = extraer_valor("Idioma original")
    fecha_estreno = extraer("Fecha de publicaci√≥n/estreno")
    compositor = extraer_valor("Compositor")
    editor = extraer_valor("Editor")
    costo_produccion = extraer_valor("Costo de producci√≥n")
    ingresos_brutos = extraer_valor("Ingresos brutos")
    titulo_oficial = extraer_valor("T√≠tulo oficial")

    # Informaci√≥n de director
    if director:
        partes.append(f"dirigido por {', '.join(set(director))}")

    # Informaci√≥n de guionista
    if guionista:
        partes.append(f"escrito por {', '.join(set(guionista))}")

    # Informaci√≥n de reparto
    if reparto:
        partes.append(f"con la participaci√≥n de {', '.join(set(reparto))}")

    # Informaci√≥n de productora
    if productora:
        partes.append(f"producido por {', '.join(set(productora))}")

    # Informaci√≥n de idioma original
    if idioma_original:
        partes.append(f"en idioma original {', '.join(set(idioma_original))}")

    # Informaci√≥n de fecha de estreno
    if fecha_estreno:
        partes.append(f"estrenado el {fecha_estreno[0].replace('Fecha de publicaci√≥n/estreno: +', '').split('T')[0]}")

    # Informaci√≥n de compositor
    if compositor:
        partes.append(f"con m√∫sica de {', '.join(set(compositor))}")

    # Informaci√≥n de editor
    if editor:
        partes.append(f"editado por {', '.join(set(editor))}")

    # Informaci√≥n de costo de producci√≥n
    if costo_produccion:
        partes.append(f"con un costo de producci√≥n de {', '.join(set(costo_produccion))}")

    # Informaci√≥n de ingresos brutos
    if ingresos_brutos:
        partes.append(f"y unos ingresos brutos de {', '.join(set(ingresos_brutos))}")

    # Informaci√≥n de t√≠tulo oficial
    if titulo_oficial:
        partes.append(f"con el t√≠tulo oficial {', '.join(set(titulo_oficial))}")

    # Datos de libros y obras
    autor = extraer_valor("Autor")
    fecha_publicacion = extraer("Fecha de publicaci√≥n")
    ilustrador = extraer_valor("Ilustrador")
    lugar_publicacion = extraer_valor("Lugar de publicaci√≥n")
    idioma_obra = extraer_valor("Idioma de la obra")
    titulo_oficial_obra = extraer_valor("T√≠tulo oficial")
    descripcion_corta = extraer_valor("Descripci√≥n corta")
    editorial = extraer_valor("Editorial")
    titulo_original = extraer_valor("T√≠tulo original")
    editor_literario = extraer_valor("Editor literario")

    # Informaci√≥n de autor
    if autor:
        partes.append(f"escrito por {', '.join(set(autor))}")

    # Informaci√≥n de fecha de publicaci√≥n
    if fecha_publicacion:
        partes.append(f"publicado el {fecha_publicacion[0].replace('Fecha de publicaci√≥n: +', '').split('T')[0]}")

    # Informaci√≥n de ilustrador
    if ilustrador:
        partes.append(f"con ilustraciones de {', '.join(set(ilustrador))}")

    # Informaci√≥n de lugar de publicaci√≥n
    if lugar_publicacion:
        partes.append(f"publicado en {', '.join(set(lugar_publicacion))}")

    # Informaci√≥n de idioma de la obra
    if idioma_obra:
        partes.append(f"en el idioma {', '.join(set(idioma_obra))}")

    # Informaci√≥n de t√≠tulo oficial
    if titulo_oficial_obra:
        partes.append(f"con el t√≠tulo oficial {', '.join(set(titulo_oficial_obra))}")

    # Informaci√≥n de descripci√≥n corta
    if descripcion_corta:
        partes.append(f"su descripci√≥n corta es: {', '.join(set(descripcion_corta))}")

    # Informaci√≥n de editorial
    if editorial:
        partes.append(f"publicado por {', '.join(set(editorial))}")

    # Informaci√≥n de t√≠tulo original
    if titulo_original:
        partes.append(f"con el t√≠tulo original {', '.join(set(titulo_original))}")

    # Informaci√≥n de editor literario
    if editor_literario:
        partes.append(f"editado por {', '.join(set(editor_literario))}")

    # Datos de organizaciones y empresas
    fundador = extraer_valor("Fundador")
    sede = extraer_valor("Sede")
    fecha_fundacion = extraer("Fecha de fundaci√≥n")
    industria = extraer_valor("Industria")
    accionista = extraer_valor("Accionista")
    propietario = extraer_valor("Propietario")
    empresa_matriz = extraer_valor("Empresa matriz")
    empleados = extraer_valor("Empleados")
    recuento_ingresos = extraer_valor("Recuento de ingresos")
    autoridad_reguladora = extraer_valor("Autoridad reguladora")

    # Informaci√≥n de fundador
    if fundador:
        partes.append(f"fundada por {', '.join(set(fundador))}")

    # Informaci√≥n de sede
    if sede:
        partes.append(f"su sede se encuentra en {', '.join(set(sede))}")

    # Informaci√≥n de fecha de fundaci√≥n
    if fecha_fundacion:
        partes.append(f"fundada el {fecha_fundacion[0].replace('Fecha de fundaci√≥n: +', '').split('T')[0]}")

    # Informaci√≥n de industria
    if industria:
        partes.append(f"pertenece a la industria de {', '.join(set(industria))}")

    # Informaci√≥n de accionistas
    if accionista:
        partes.append(f"con accionistas como {', '.join(set(accionista))}")

    # Informaci√≥n de propietario
    if propietario:
        partes.append(f"es propiedad de {', '.join(set(propietario))}")

    # Informaci√≥n de empresa matriz
    if empresa_matriz:
        partes.append(f"forma parte del grupo {', '.join(set(empresa_matriz))}")

    # Informaci√≥n de empleados
    if empleados:
        partes.append(f"emplea a {', '.join(set(empleados))}")

    # Informaci√≥n de recuento de ingresos
    if recuento_ingresos:
        partes.append(f"con un recuento de ingresos de {', '.join(set(recuento_ingresos))}")

    # Informaci√≥n de autoridad reguladora
    if autoridad_reguladora:
        partes.append(f"y est√° regulada por {', '.join(set(autoridad_reguladora))}")

    # Lugar
    pais = extraer_valor("Pa√≠s")
    ubicacion_administrativa = extraer_valor("Ubicaci√≥n administrativa")
    coordenadas = extraer_valor("Coordenadas")
    area = extraer_valor("√Årea")
    poblacion = extraer_valor("Poblaci√≥n")
    pagina_web = extraer_valor("P√°gina web oficial")
    nombre_oficial = extraer_valor("Nombre oficial")
    categoria_patrimonio = extraer_valor("Categor√≠a de patrimonio")

    # Informaci√≥n de pa√≠s
    if pais:
        partes.append(f"se encuentra en {', '.join(set(pais))}")

    # Informaci√≥n de ubicaci√≥n administrativa
    if ubicacion_administrativa:
        partes.append(f"ubicado en la {', '.join(set(ubicacion_administrativa))}")

    # Informaci√≥n de coordenadas
    if coordenadas:
        partes.append(f"con coordenadas {', '.join(set(coordenadas))}")

    # Informaci√≥n de √°rea
    if area:
        partes.append(f"con un √°rea de {', '.join(set(area))} km¬≤")

    # Informaci√≥n de poblaci√≥n
    if poblacion:
        partes.append(f"con una poblaci√≥n de {', '.join(set(poblacion))}")

    # Informaci√≥n de p√°gina web
    if pagina_web:
        partes.append(f"su p√°gina web oficial es {', '.join(set(pagina_web))}")

    # Informaci√≥n de nombre oficial
    if nombre_oficial:
        partes.append(f"su nombre oficial es {', '.join(set(nombre_oficial))}")

    # Informaci√≥n de categor√≠a de patrimonio
    if categoria_patrimonio:
        partes.append(f"y est√° clasificado como {', '.join(set(categoria_patrimonio))} en t√©rminos de patrimonio")

    # Datos astron√≥micos
    clase_espectral = extraer_valor("Clase espectral")
    gravedad_superficial = extraer_valor("Gravedad superficial")
    masa = extraer_valor("Masa")
    orbita = extraer_valor("√ìrbita")
    diametro = extraer_valor("Di√°metro")
    orbita_de = extraer_valor("√ìrbita de")
    luna_de = extraer_valor("Luna de")
    orbita_alrededor_de = extraer_valor("√ìrbita alrededor de")
    coordenadas_celestes = extraer_valor("Coordenadas celestes")
    constelacion = extraer_valor("Constelaci√≥n")

    # Informaci√≥n de clase espectral
    if clase_espectral:
        partes.append(f"su clase espectral es {', '.join(set(clase_espectral))}")

    # Informaci√≥n de gravedad superficial
    if gravedad_superficial:
        partes.append(f"su gravedad superficial es de {', '.join(set(gravedad_superficial))} m/s¬≤")

    # Informaci√≥n de masa
    if masa:
        partes.append(f"su masa es {', '.join(set(masa))} kg")

    # Informaci√≥n de √≥rbita
    if orbita:
        partes.append(f"su √≥rbita es {', '.join(set(orbita))}")

    # Informaci√≥n de di√°metro
    if diametro:
        partes.append(f"su di√°metro es de {', '.join(set(diametro))} km")

    # Informaci√≥n de √≥rbita de
    if orbita_de:
        partes.append(f"orbita alrededor de {', '.join(set(orbita_de))}")

    # Informaci√≥n de luna de
    if luna_de:
        partes.append(f"es luna de {', '.join(set(luna_de))}")

    # Informaci√≥n de √≥rbita alrededor de
    if orbita_alrededor_de:
        partes.append(f"orbita alrededor de {', '.join(set(orbita_alrededor_de))}")

    # Informaci√≥n de coordenadas celestes
    if coordenadas_celestes:
        partes.append(f"sus coordenadas celestes son {', '.join(set(coordenadas_celestes))}")

    # Informaci√≥n de constelaci√≥n
    if constelacion:
        partes.append(f"pertenece a la constelaci√≥n de {', '.join(set(constelacion))}")

    # Datos de relaciones y colaboraciones
    parte_de = extraer_valor("Parte de")
    tiene_como_parte = extraer_valor("Tiene como parte")
    fabricante = extraer_valor("Fabricante")
    patrocinado_por = extraer_valor("Patrocinado por")
    participante = extraer_valor("Participante")
    predecesor = extraer_valor("Predecesor")
    sucesor = extraer_valor("Sucesor")
    basado_en = extraer_valor("Basado en")
    autor_obra = extraer_valor("Autor de la obra")
    version_edicion = extraer_valor("Versi√≥n o edici√≥n de")

    # Informaci√≥n de parte de
    if parte_de:
        partes.append(f"es parte de {', '.join(set(parte_de))}")

    # Informaci√≥n de tiene como parte
    if tiene_como_parte:
        partes.append(f"tiene como parte {', '.join(set(tiene_como_parte))}")

    # Informaci√≥n de fabricante
    if fabricante:
        partes.append(f"fue fabricado por {', '.join(set(fabricante))}")

    # Informaci√≥n de patrocinado por
    if patrocinado_por:
        partes.append(f"fue patrocinado por {', '.join(set(patrocinado_por))}")

    # Informaci√≥n de participante
    if participante:
        partes.append(f"particip√≥ en {', '.join(set(participante))}")

    # Informaci√≥n de predecesor
    if predecesor:
        partes.append(f"su predecesor fue {', '.join(set(predecesor))}")

    # Informaci√≥n de sucesor
    if sucesor:
        partes.append(f"su sucesor fue {', '.join(set(sucesor))}")

    # Informaci√≥n de basado en
    if basado_en:
        partes.append(f"est√° basado en {', '.join(set(basado_en))}")

    # Informaci√≥n de autor de la obra
    if autor_obra:
        partes.append(f"fue obra de {', '.join(set(autor_obra))}")

    # Informaci√≥n de versi√≥n o edici√≥n de
    if version_edicion:
        partes.append(f"es una versi√≥n o edici√≥n de {', '.join(set(version_edicion))}")

    # Datos de deportes
    miembro_equipo = extraer_valor("Miembro de equipo deportivo")
    numero_victorias = extraer_valor("N√∫mero de victorias")
    numero_derrotas = extraer_valor("N√∫mero de derrotas")
    deporte_practicado = extraer_valor("Deporte practicado")

    # Informaci√≥n de miembro de equipo deportivo
    if miembro_equipo:
        partes.append(f"fue miembro de {', '.join(set(miembro_equipo))}")

    # Informaci√≥n de n√∫mero de victorias
    if numero_victorias:
        partes.append(f"tiene {', '.join(set(numero_victorias))} victorias")

    # Informaci√≥n de n√∫mero de derrotas
    if numero_derrotas:
        partes.append(f"y {', '.join(set(numero_derrotas))} derrotas")

    # Informaci√≥n de deporte practicado
    if deporte_practicado:
        partes.append(f"practic√≥ {', '.join(set(deporte_practicado))}")

    # Datos musicales
    numero_catalogo = extraer_valor("N√∫mero de cat√°logo")
    id_musicbrainz = extraer_valor("ID MusicBrainz")

    # Informaci√≥n de n√∫mero de cat√°logo
    if numero_catalogo:
        partes.append(f"su n√∫mero de cat√°logo es {', '.join(set(numero_catalogo))}")

    # Informaci√≥n de ID MusicBrainz
    if id_musicbrainz:
        partes.append(f"su ID en MusicBrainz es {', '.join(set(id_musicbrainz))}")

    # Datos de tecnolog√≠a/software
    desarrollador = extraer_valor("Desarrollador")
    version = extraer_valor("Versi√≥n")
    licencia = extraer_valor("Licencia")
    sitio_web = extraer_valor("Sitio web oficial del software")

    # Informaci√≥n de desarrollador
    if desarrollador:
        partes.append(f"fue desarrollado por {', '.join(set(desarrollador))}")

    # Informaci√≥n de versi√≥n
    if version:
        partes.append(f"su versi√≥n es {', '.join(set(version))}")

    # Informaci√≥n de licencia
    if licencia:
        partes.append(f"su licencia es {', '.join(set(licencia))}")

    # Informaci√≥n de sitio web oficial
    if sitio_web:
        partes.append(f"su sitio web oficial es {', '.join(set(sitio_web))}")

    # üèõ Cultura / Historia
    lugar_exposicion = extraer_valor("Lugar de exposici√≥n")
    periodo_historico = extraer_valor("Per√≠odo hist√≥rico")
    proyecto_artistico = extraer_valor("Proyecto art√≠stico")

    # ü¶† Biolog√≠a / Ciencia
    especie = extraer_valor("Especie")
    organismo_relacionado = extraer_valor("Organismo relacionado")
    funcion_biologica = extraer_valor("Funci√≥n biol√≥gica")
    propiedades_geneticas = extraer_valor("Propiedades gen√©ticas")

    # Informaci√≥n de lugar de exposici√≥n
    if lugar_exposicion:
        partes.append(f"se expuso en {', '.join(set(lugar_exposicion))}")

    # Informaci√≥n de per√≠odo hist√≥rico
    if periodo_historico:
        partes.append(f"pertenece al per√≠odo hist√≥rico de {', '.join(set(periodo_historico))}")

    # Informaci√≥n de proyecto art√≠stico
    if proyecto_artistico:
        partes.append(f"fue parte del proyecto art√≠stico {', '.join(set(proyecto_artistico))}")

    # Informaci√≥n de especie
    if especie:
        partes.append(f"pertenece a la especie {', '.join(set(especie))}")

    # Informaci√≥n de organismo relacionado
    if organismo_relacionado:
        partes.append(f"est√° relacionado con {', '.join(set(organismo_relacionado))}")

    # Informaci√≥n de funci√≥n biol√≥gica
    if funcion_biologica:
        partes.append(f"su funci√≥n biol√≥gica es {', '.join(set(funcion_biologica))}")

    # Informaci√≥n de propiedades gen√©ticas
    if propiedades_geneticas:
        partes.append(f"tiene las siguientes propiedades gen√©ticas: {', '.join(set(propiedades_geneticas))}")

    # üöó Veh√≠culos / Transportes
    compania_aerea = extraer_valor("Compa√±√≠a a√©rea")
    propietario_vehiculo = extraer_valor("Propietario del veh√≠culo")
    tipo_transporte = extraer_valor("Tipo de transporte")

    # üè† Construcci√≥n / Arquitectura
    tipo_edificio = extraer_valor("Tipo de edificio")
    material_construccion = extraer_valor("Material de construcci√≥n")
    arquitecto = extraer_valor("Arquitecto")

    # üçΩ Alimentos
    ingrediente_principal = extraer_valor("Ingrediente principal")
    metodo_preparacion = extraer_valor("M√©todo de preparaci√≥n")

    # Informaci√≥n de compa√±√≠a a√©rea
    if compania_aerea:
        partes.append(f"es operado por la compa√±√≠a a√©rea {', '.join(set(compania_aerea))}")

    # Informaci√≥n de propietario del veh√≠culo
    if propietario_vehiculo:
        partes.append(f"su propietario es {', '.join(set(propietario_vehiculo))}")

    # Informaci√≥n de tipo de transporte
    if tipo_transporte:
        partes.append(f"es un {', '.join(set(tipo_transporte))}")

    # Informaci√≥n de tipo de edificio
    if tipo_edificio:
        partes.append(f"es un tipo de edificio {', '.join(set(tipo_edificio))}")

    # Informaci√≥n de material de construcci√≥n
    if material_construccion:
        partes.append(f"est√° construido con {', '.join(set(material_construccion))}")

    # Informaci√≥n de arquitecto
    if arquitecto:
        partes.append(f"fue dise√±ado por {', '.join(set(arquitecto))}")

    # Informaci√≥n de ingrediente principal
    if ingrediente_principal:
        partes.append(f"su ingrediente principal es {', '.join(set(ingrediente_principal))}")

    # Informaci√≥n de m√©todo de preparaci√≥n
    if metodo_preparacion:
        partes.append(f"su m√©todo de preparaci√≥n es {', '.join(set(metodo_preparacion))}")

    # üåø Medio ambiente / Naturaleza
    habita_en = extraer_valor("Habita en")
    requiere = extraer_valor("Requiere")

    # üí° Invenciones
    nombre_invento = extraer_valor("Nombre del invento")
    patente = extraer_valor("Patente")

    # Informaci√≥n de h√°bitat
    if habita_en:
        partes.append(f"habita en {', '.join(set(habita_en))}")

    # Informaci√≥n de requisitos
    if requiere:
        partes.append(f"requiere {', '.join(set(requiere))}")

    # Informaci√≥n de nombre del invento
    if nombre_invento:
        partes.append(f"su invento se llama {', '.join(set(nombre_invento))}")

    # Informaci√≥n de patente
    if patente:
        partes.append(f"su patente es {', '.join(set(patente))}")

    resumen += ", " + ", ".join(partes) + "."

    return resumen



def predecir_nli(premisa, hipotesis):
    inputs = tokenizer(premisa, hipotesis, return_tensors="pt", truncation=True)
    with torch.no_grad():
        logits = model(**inputs).logits
    probs = torch.softmax(logits, dim=1).squeeze().tolist()
    etiquetas = ["contradiction", "neutral", "entailment"]
    prediccion = etiquetas[torch.argmax(logits)]
    return prediccion, probs

def predecir_nli_traducido(premisa_es, hipotesis_es):
    # Traducimos ambas al ingl√©s
    #print(premisa_es)
    premisa_en = traducir_es_en(premisa_es)
    #print(premisa_en)
    hipotesis_en = traducir_es_en(hipotesis_es)
    #print(hipotesis_en)

    # Hacemos predicci√≥n con el modelo NLI en ingl√©s
    inputs = tokenizer_nli(premisa_en, hipotesis_en, return_tensors="pt", truncation=True)
    with torch.no_grad():
        logits = modelo_nli(**inputs).logits
    probs = torch.softmax(logits, dim=1).squeeze().tolist()
    etiquetas = ["contradiction", "neutral", "entailment"]
    prediccion = etiquetas[torch.argmax(logits)]
    return prediccion, probs



def predecir_con_oracion(evidencia_es, hipotesis_es):
    pred, probs = predecir_nli_traducido(evidencia_es, hipotesis_es)
    return pred, probs


def extraer_oraciones_jsonl(path_archivo):
    oraciones = []
    with open(path_archivo, 'r', encoding='utf-8') as archivo:
        for linea in archivo:
            if linea.strip():  # Ignorar l√≠neas vac√≠as
                datos = json.loads(linea)
                oracion = datos.get("claim_es")
                if oracion:
                    oraciones.append(oracion)
    return oraciones


def extraer_sujetos_prueba():
    ruta_entrada = "../datasets/dataset_espanol.jsonl"
    ruta_salida = "../resultados_pruebas/sujetos.jsonl"
    numero_oracion = 0

    oraciones = extraer_oraciones_jsonl(ruta_entrada)

    with open(ruta_salida, 'w', encoding='utf-8') as f_out:
        for oracion in oraciones:
            numero_oracion += 1
            print(f"Oracion: {numero_oracion}/2000")
            sujeto = extraer_sujeto(oracion)
            qid, label, descripcion = buscar_entidad_wikidata(sujeto) if sujeto else (None, None, None)

            estado = "correct" if sujeto and qid else "error"

            resultado = {
                "oracion": oracion,
                "sujeto": sujeto,
                "qid": qid,
                "estado": estado
            }

            f_out.write(json.dumps(resultado, ensure_ascii=False) + '\n')
            f_out.flush()  # Asegura que se escribe en tiempo real

def extraer_sujetos_prueba_openai():
    ruta_entrada = "../datasets/dataset_espanol.jsonl"
    ruta_salida = "../resultados_pruebas/sujetos_openai.jsonl"
    numero_oracion = 0

    oraciones = extraer_oraciones_jsonl(ruta_entrada)

    with open(ruta_salida, 'w', encoding='utf-8') as f_out:
        for oracion in oraciones:
            numero_oracion += 1
            print(f"Oracion: {numero_oracion}/2000")
            sujeto = extraer_sujeto_openai(oracion)
            qid, label, descripcion = buscar_entidad_wikidata(sujeto) if sujeto else (None, None, None)

            estado = "correct" if sujeto and qid else "error"

            resultado = {
                "oracion": oracion,
                "sujeto": sujeto,
                "qid": qid,
                "estado": estado
            }

            f_out.write(json.dumps(resultado, ensure_ascii=False) + '\n')
            f_out.flush()  # Asegura que se escribe en tiempo real

def combinar_claims_con_qid(ruta_entrada, ruta_sujetos):
    # Cargar sujetos en un diccionario para acceso r√°pido por oraci√≥n
    sujetos_dict = {}
    with open(ruta_sujetos, 'r', encoding='utf-8') as f:
        for linea in f:
            entrada = json.loads(linea)
            sujetos_dict[entrada['oracion']] = {
                'qid': entrada['qid'],
                'sujeto': entrada['sujeto']
            }

    # Combinar datos
    combinados = []
    with open(ruta_entrada, 'r', encoding='utf-8') as f:
        for linea in f:
            entrada = json.loads(linea)
            claim = entrada['claim_es']
            label = entrada['label']
            info_sujeto = sujetos_dict.get(claim)

            if info_sujeto:  # Solo si se encontr√≥ qid y sujeto correspondiente
                combinados.append({
                    'claim_es': claim,
                    'label': label,
                    'qid': info_sujeto['qid'],
                    'sujeto': info_sujeto['sujeto']
                })

    return combinados

import json

def benchmark_con_spacy():
    ruta_entrada = "../datasets/dataset_espanol.jsonl"
    ruta_sujetos = "../resultados_pruebas/sujetos.jsonl"
    ruta_salida = "../resultados_pruebas/benchmark_spacy.jsonl"
    
    datos = combinar_claims_con_qid(ruta_entrada, ruta_sujetos)

    with open(ruta_salida, 'w', encoding='utf-8') as f_salida:
        pass  # Limpiamos el archivo antes de empezar

    for dato in datos:
        oracion = dato["claim_es"]
        resultado_correcto = dato["label"]
        qid = dato["qid"]
        sujeto = dato["sujeto"]

        print(dato)

        if qid:
            hechos = recuperar_hechos(qid)
            tipos_qids = obtener_tipo_entidad(qid)
            tipos_etiquetas = resolver_qids(tipos_qids)
            oracion_datos = generar_oracion_resumen_con_etiquetas(sujeto, hechos, tipos_etiquetas)
            pred, probs = predecir_con_oracion(oracion_datos, oracion)

            resultado = {
                "oracion": oracion,
                "entidad": sujeto,
                "oracion_creada": oracion_datos,
                "prediccion": pred,
                "confianza": probs,
                "resultado_correcto": resultado_correcto
            }

            with open(ruta_salida, 'a', encoding='utf-8') as f_salida:
                f_salida.write(json.dumps(resultado, ensure_ascii=False) + '\n')

def benchmark_con_openai():
    ruta_entrada = "../datasets/dataset_espanol.jsonl"
    ruta_sujetos = "../resultados_pruebas/sujetos_openai.jsonl"
    ruta_salida = "../resultados_pruebas/benchmark_openai.jsonl"
    
    datos = combinar_claims_con_qid(ruta_entrada, ruta_sujetos)

    with open(ruta_salida, 'w', encoding='utf-8') as f_salida:
        pass  # Limpiamos el archivo antes de empezar

    for dato in datos:
        oracion = dato["claim_es"]
        resultado_correcto = dato["label"]
        qid = dato["qid"]
        sujeto = dato["sujeto"]

        print(dato)

        if qid:
            hechos = recuperar_hechos(qid)
            tipos_qids = obtener_tipo_entidad(qid)
            tipos_etiquetas = resolver_qids(tipos_qids)
            oracion_datos = generar_oracion_resumen_con_etiquetas(sujeto, hechos, tipos_etiquetas)
            pred, probs = predecir_con_oracion(oracion_datos, oracion)

            resultado = {
                "oracion": oracion,
                "entidad": sujeto,
                "oracion_creada": oracion_datos,
                "prediccion": pred,
                "confianza": probs,
                "resultado_correcto": resultado_correcto
            }

            with open(ruta_salida, 'a', encoding='utf-8') as f_salida:
                f_salida.write(json.dumps(resultado, ensure_ascii=False) + '\n')



def analizar_texto(texto):
    oraciones = dividir_en_oraciones(texto)
    resultados = []
    entidad_anterior = None
    oracion_anterior = None
    hechos_anterior = []
    numero_oraciones = 0

    for oracion in oraciones:
        if oracion != "":
            numero_oraciones += 1
            #print(f"\n--- Analizando oraci√≥n ---\n{oracion}")
            sujeto = extraer_sujeto(oracion)

            if sujeto:
                qid, label, descripcion = buscar_entidad_wikidata(sujeto)
                if qid:
                    hechos = recuperar_hechos(qid)
                    tipos_qids = obtener_tipo_entidad(qid)
                    tipos_etiquetas = resolver_qids(tipos_qids)
                    oracion_datos = generar_oracion_resumen_con_etiquetas(sujeto,hechos, tipos_etiquetas)
                    entidad_anterior = label
                    hechos_anterior = hechos
                    oracion_anterior = oracion_datos

                else:
                    hechos = []
                    #oracion_datos = ""
            else:
                sujeto = entidad_anterior
                hechos = hechos_anterior
                oracion_datos = oracion_anterior

            pred, probs = predecir_con_oracion(oracion_datos, oracion)

            resultados.append({
                "oracion": oracion,
                "entidad": sujeto,
                "hechos": hechos,
                "oracion_creada": oracion_datos,
                "prediccion": pred,
                "confianza": probs
            })

            #print(f"Entidad     : {sujeto}")
            #print(f"Hechos      : {hechos}")
            #print(f"Oracion      : {oracion_datos}")
            #print(f"Predicci√≥n  : {pred} | Confianza: {probs}")

    return resultados, numero_oraciones

def procesar_texto(texto):
    resultados, numero_oraciones = analizar_texto(texto)

    conteo = {
        "contradiction": 0,
        "neutral": 0,
        "entailment": 0
    }

    oraciones_etiquetadas = []

    for resultado in resultados:
        pred = resultado["prediccion"]
        conteo[pred] += 1

        oracion = resultado["oracion"]

        if pred == "contradiction":
            oracion = f'<span class="subrayado-contradiction">{oracion}</span>'
        elif pred == "neutral":
            oracion = f'<span class="subrayado-neutral">{oracion}</span>'
        else:
            oracion = f'<span class="subrayado-correcto">{oracion}</span>'

        oraciones_etiquetadas.append(oracion)

    texto_etiquetado = ' '.join(oraciones_etiquetadas)

    return {
        "total_oraciones": numero_oraciones,
        "n_contradiccion": conteo["contradiction"],
        "n_neutral": conteo["neutral"],
        "n_entailment": conteo["entailment"],
        "texto_etiquetado": texto_etiquetado
    }


# Ejemplo de uso
if __name__ == "__main__":

    '''
        texto = """
    El poeta Miguel Hernandez no naci√≥ en Espa√±a. 
    Escribi√≥ Cien a√±os de soledad. 
    Gabriel Garc√≠a M√°rquez no escribi√≥ Cien a√±os de soledad. 
    Gabriel Garc√≠a M√°rquez gan√≥ el Premio Nobel de Literatura en 1982. 
    Gabriel Garc√≠a M√°rquez fue un escritor destacado.
    Tierra gira alrededor del Sol.
    """
    analizar_texto(texto)


    benchmark_con_openai()
    benchmark_con_spacy()

    texto = sys.stdin.read()
    resultado = procesar_texto(texto)
    print(json.dumps(resultado))

    '''

    texto = sys.stdin.read()
    resultado = procesar_texto(texto)
    print(json.dumps(resultado))

